{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Weather Prediction Using Recurrent Neural Networks\n",
    "\n",
    "## Adrian, Ben, and Sai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bgree\\Miniconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from functools import reduce\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Read in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Filenames\n",
    "city_file = 'city_attributes.csv'\n",
    "temp_file = 'temperature.csv'\n",
    "humid_file = 'humidity.csv'\n",
    "press_file = 'pressure.csv'\n",
    "desc_file = 'weather_description.csv'\n",
    "wdir_file = 'wind_direction.csv'\n",
    "wspeed_file = 'wind_speed.csv'\n",
    "# Load the files\n",
    "city_df = pd.read_csv(city_file)\n",
    "city_df.rename(str.lower, axis = 'columns', inplace = True)\n",
    "city_df.drop(['country'], axis = 1, inplace = True)\n",
    "city_df.set_index(['city'], inplace = True)\n",
    "temp_df = pd.read_csv(temp_file)\n",
    "humid_df = pd.read_csv(humid_file)\n",
    "press_df = pd.read_csv(press_file)\n",
    "desc_df = pd.read_csv(desc_file)\n",
    "wdir_df = pd.read_csv(wdir_file)\n",
    "wspeed_df = pd.read_csv(wspeed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# These are the cities that universally have > 1% missing across all weather values\n",
    "drop_city = set(temp_df.columns[temp_df.isna().sum() > 500]) & \\\n",
    "set(humid_df.columns[humid_df.isna().sum() > 500]) & \\\n",
    "set(press_df.columns[press_df.isna().sum() > 500]) & \\\n",
    "set(desc_df.columns[desc_df.isna().sum() > 500]) & \\\n",
    "set(wdir_df.columns[wdir_df.isna().sum() > 500]) & \\\n",
    "set(wspeed_df.columns[wspeed_df.isna().sum() > 500])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the undesired cities and melt the tables to be conducive for joining\n",
    "alt_temp_df = pd.melt(temp_df.drop(drop_city, axis = 1), id_vars = ['datetime'], var_name = 'city', value_name = 'temperature')\n",
    "alt_humid_df = pd.melt(humid_df.drop(drop_city, axis = 1), id_vars = ['datetime'], var_name = 'city', value_name = 'humidity')\n",
    "alt_press_df = pd.melt(press_df.drop(drop_city, axis = 1), id_vars = ['datetime'], var_name = 'city', value_name = 'pressure')\n",
    "alt_desc_df = pd.melt(desc_df.drop(drop_city, axis = 1), id_vars = ['datetime'], var_name = 'city', value_name = 'weather_description')\n",
    "alt_wdir_df = pd.melt(wdir_df.drop(drop_city, axis = 1), id_vars = ['datetime'], var_name = 'city', value_name = 'wind_direction')\n",
    "alt_wspeed_df = pd.melt(wspeed_df.drop(drop_city, axis = 1), id_vars = ['datetime'], var_name = 'city', value_name = 'wind_speed')\n",
    "\n",
    "# Set proper indices\n",
    "alt_temp_df = alt_temp_df.set_index(['city', 'datetime'])\n",
    "alt_humid_df = alt_humid_df.set_index(['city', 'datetime'])\n",
    "alt_press_df = alt_press_df.set_index(['city', 'datetime'])\n",
    "alt_desc_df = alt_desc_df.set_index(['city', 'datetime'])\n",
    "alt_wdir_df = alt_wdir_df.set_index(['city', 'datetime'])\n",
    "alt_wspeed_df = alt_wspeed_df.set_index(['city', 'datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Join tables together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Join tables on the city and datetime info\n",
    "dfs = [city_df, alt_temp_df, alt_humid_df, alt_press_df, alt_wspeed_df, alt_wdir_df, alt_desc_df]\n",
    "df_final = reduce(lambda left, right : pd.merge(left, right, left_index = True, right_index = True), dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deal with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# INTERPOLATION HAPPENS HERE -- Break up by city\n",
    "df_final = df_final.groupby('city').apply(lambda group: group.interpolate(limit_direction = 'both'))\n",
    "\n",
    "# Need to do something special for weather_description\n",
    "arr, cat = df_final['weather_description'].factorize()\n",
    "df_final['weather_description'] = pd.Series(arr).replace(-1, np.nan).\\\n",
    "interpolate(method = 'nearest', limit_direction = 'both')\\\n",
    ".interpolate(limit_direction = 'both').astype('category')\\\n",
    ".cat.rename_categories(cat).astype('str').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# The whole purpose here is to encode wind direction. It's not continuous so don't really want to scale it\n",
    "# Also have more granularity in wind dir if need be.\n",
    "#dir_df = pd.DataFrame({'dir' : ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE', 'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW', 'N'],\n",
    "#                        'lower' : [348.75, 11.25, 33.75, 56.25, 78.75, 101.25, 123.75, 146.25, 168.75, 191.25, 213.75, 236.25, 258.75, 281.25, 303.75, 326.25, 0],\n",
    "#                        'upper' : [360, 33.75, 56.25, 78.75, 101.25, 123.75, 146.25, 168.75, 191.25, 213.75, 236.25, 258.75, 281.25, 303.75, 326.25, 348.75, 11.25]})\n",
    "dir_df = pd.DataFrame({'dir' : ['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW', 'N'],\n",
    "                        'lower' : [337.5, 22.5, 67.5, 112.5, 157, 202.5, 247.5, 292.5, 0],\n",
    "                        'upper' : [360, 67.5, 112.5, 157, 202.5, 247.5, 292.5, 337.5, 22.5]})\n",
    "# Make a copy to fool around in\n",
    "fill_this = df_final['wind_direction'].copy()\n",
    "# And overwrite the copy\n",
    "for i in reversed(range(len(dir_df))):\n",
    "#    print(str(dir_df.loc[i,'lower']) + \" and \" + str(dir_df.loc[i,'upper']))\n",
    "    fill_this.loc[df_final['wind_direction'].between(dir_df.loc[i,'lower'], dir_df.loc[i,'upper'])] = i\n",
    "# This is a bit ugly here; but it maintains any missing values nicely\n",
    "df_final['wind_direction'] = dir_df.loc[fill_this, 'dir'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Go ahead and drop lat and long, we wont need them for now\n",
    "df_final.drop([\"latitude\", \"longitude\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the data to Farenheit and note the min and max values\n",
    "df_final[\"temperature\"] = df_final[\"temperature\"] * 9/5 - 459.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Normalize data through min-max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>weather_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Portland</th>\n",
       "      <th>2012-10-01 12:00:00</th>\n",
       "      <td>0.503824</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>scattered clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01 13:00:00</th>\n",
       "      <td>0.503824</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>scattered clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01 14:00:00</th>\n",
       "      <td>0.503865</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>scattered clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01 15:00:00</th>\n",
       "      <td>0.503975</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>scattered clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01 16:00:00</th>\n",
       "      <td>0.504084</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>scattered clouds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              temperature  humidity  pressure  wind_speed  \\\n",
       "city     datetime                                                           \n",
       "Portland 2012-10-01 12:00:00     0.503824  0.800000  0.746667         0.0   \n",
       "         2012-10-01 13:00:00     0.503824  0.800000  0.746667         0.0   \n",
       "         2012-10-01 14:00:00     0.503865  0.789474  0.746667         0.0   \n",
       "         2012-10-01 15:00:00     0.503975  0.789474  0.746667         0.0   \n",
       "         2012-10-01 16:00:00     0.504084  0.789474  0.746667         0.0   \n",
       "\n",
       "                             wind_direction weather_description  \n",
       "city     datetime                                                \n",
       "Portland 2012-10-01 12:00:00              N    scattered clouds  \n",
       "         2012-10-01 13:00:00              N    scattered clouds  \n",
       "         2012-10-01 14:00:00              N    scattered clouds  \n",
       "         2012-10-01 15:00:00              N    scattered clouds  \n",
       "         2012-10-01 16:00:00             NE    scattered clouds  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling happens here -- IMPUTATION MUST HAPPEN FIRST\n",
    "scale_df = df_final[['temperature', 'humidity', 'pressure', 'wind_speed']].values\n",
    "scaler = MinMaxScaler()\n",
    "# We have access to min and max so we can transform back and forth\n",
    "scale_df = scaler.fit_transform(scale_df)\n",
    "df_final_scaled = df_final.copy()\n",
    "df_final_scaled[['temperature', 'humidity', 'pressure', 'wind_speed']] = scale_df\n",
    "df_final_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Collapse a lot of these groupings\n",
    "weather_dict = {'scattered clouds' : 'partly_cloudy', 'sky is clear' : 'clear', \n",
    "             'few clouds' : 'partly_cloudy', 'broken clouds' : 'partly_cloudy',\n",
    "           'overcast clouds' : 'cloudy', 'mist' : 'cloudy', 'haze' : 'cloudy', \n",
    "             'dust' : 'other', 'fog' : 'cloudy', 'moderate rain' : 'rain',\n",
    "           'light rain' : 'rain', 'heavy intensity rain' : 'rain', 'light intensity drizzle' : 'rain',\n",
    "           'heavy snow' : 'snow', 'snow' : 'snow', 'light snow' : 'snow', 'very heavy rain' : 'rain',\n",
    "           'thunderstorm' : 'tstorm', 'proximity thunderstorm' : 'tstorm', 'smoke' : 'other', 'freezing rain' : 'snow',\n",
    "           'thunderstorm with light rain' : 'tstorm', 'drizzle' : 'rain', 'sleet' : 'snow',\n",
    "           'thunderstorm with rain' : 'tstorm', 'thunderstorm with heavy rain' : 'tstorm',\n",
    "           'squalls' : 'rain', 'heavy intensity drizzle' : 'rain', 'light shower snow' : 'snow',\n",
    "           'light intensity shower rain' : 'rain', 'shower rain' : 'rain',\n",
    "           'heavy intensity shower rain' : 'rain', 'proximity shower rain' : 'rain',\n",
    "           'proximity sand/dust whirls' : 'other', 'proximity moderate rain' : 'rain', 'sand' : 'other',\n",
    "           'shower snow' : 'snow', 'proximity thunderstorm with rain' : 'tstorm',\n",
    "           'sand/dust whirls' : 'other', 'proximity thunderstorm with drizzle' : 'tstorm',\n",
    "           'thunderstorm with drizzle' : 'tstorm', 'thunderstorm with light drizzle' : 'tstorm',\n",
    "           'light rain and snow' : 'snow', 'thunderstorm with heavy drizzle' : 'tstorm',\n",
    "           'ragged thunderstorm' : 'tstorm', 'tornado' : 'other', 'volcanic ash' : 'other', 'shower drizzle' : 'rain',\n",
    "           'heavy shower snow' : 'snow', 'light intensity drizzle rain' : 'rain',\n",
    "           'light shower sleet' : 'snow', 'rain and snow' : 'snow'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "adj_weather = [weather_dict[val] for val in df_final_scaled['weather_description']]\n",
    "df_final_scaled['adj_weather'] = adj_weather\n",
    "df_final_scaled = df_final_scaled.drop('weather_description', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Make weather and wind direction dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# And one-hot encode the wind_directions, NOT weather description since it is the response\n",
    "df_final_scaled = pd.get_dummies(df_final_scaled, prefix=['wind_dir', 'weather'], \n",
    "                                 columns=['wind_direction', 'adj_weather'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df_final_scaled = df_final_scaled.reset_index('city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Write for distribution\n",
    "df_final_scaled.to_csv('df_weather_scaled_encoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# Clean up the local environment\n",
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Split into train, test, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(\"df_weather_scaled_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Filter by the city of interest\n",
    "current_city = \"Charlotte\"\n",
    "\n",
    "full_df = full_df[full_df[\"city\"] == current_city]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgree\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\bgree\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\bgree\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "years = np.array([y[0:4] for y in full_df.datetime])\n",
    "\n",
    "train = full_df[years < '2016']\n",
    "valid = full_df[years == '2016']\n",
    "test = full_df[years > '2016']\n",
    "\n",
    "if(train.shape[0] + valid.shape[0] + test.shape[0] != years.shape[0]):\n",
    "    raise Exception(\"Partition did not work\")\n",
    "    \n",
    "# Drop the city and timestamp for all three\n",
    "train.drop([\"city\", \"datetime\"], inplace=True, axis=1)\n",
    "valid.drop([\"city\", \"datetime\"], inplace=True, axis=1)\n",
    "test.drop([\"city\", \"datetime\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Create observations using a sliding sequence window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 2\n",
    "\n",
    "train_x = [] \n",
    "train_y = []\n",
    "baseline_err = 0\n",
    "\n",
    "for i in range(train.shape[0] - seq_len):\n",
    "    train_x.append([x for x in train.iloc[i:i+seq_len, :].values])\n",
    "    train_y.append([y for y in train.iloc[i+1:i+seq_len+1, 0]])\n",
    "    \n",
    "    # Keep a running sum of squared error\n",
    "    baseline_err += (np.mean(train.iloc[i:i+seq_len, 0]) - train.iloc[i+1:i+seq_len+1, 0]) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper for dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5871117684326519, 0.5871139515807613]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mean squared error of the naive model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from Mohammad al Boni\n",
    "\n",
    "class DataSet(object):\n",
    "    def __init__(self, data):\n",
    "        self._num_examples = len(data.shape[0])\n",
    "        self._x = dt\n",
    "        self._y = labels\n",
    "        self._epochs_done = 0\n",
    "        self._index_in_epoch = 0\n",
    "        np.random.seed(123456)\n",
    "        # Shuffle the data\n",
    "        perm = np.arange(self._num_examples)\n",
    "        np.random.shuffle(perm)\n",
    "        self._images = self._images[perm]\n",
    "        self._labels = self._labels[perm]\n",
    "        random.seed(123456)\n",
    "    @property\n",
    "    def features(self):\n",
    "        return self._x\n",
    "    @property\n",
    "    def response(self):\n",
    "        return self._labels\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "    @property\n",
    "    def epochs_done(self):\n",
    "        return self._epochs_done\n",
    "\n",
    "    def reset_batch_index(self):\n",
    "        self._index_in_epoch = 0\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        done = False\n",
    "\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # After each epoch we update this\n",
    "            self._epochs_done += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm] \n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            done = True\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "    \n",
    "        return self._images[start:end], self._labels[start:end], done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEED TO\n",
    "#   Perform imputation on missing values -- Probably by city and day -- DONE\n",
    "#   Join the tables -- DONE\n",
    "#   Do min-max scaling -- DONE\n",
    "#   Roll up the values to the daily level -- NOT DOING (this isn't what we were planning on doing in our proposal)\n",
    "#   Encode the weather_description and wind direction as a one-hot -- DONE\n",
    "#   Get the wind direction as a categorical -- DONE\n",
    "\n",
    "# Pretty good. Have some more to do now\n",
    "#   Separate into training, testing, and validation --DONE\n",
    "#   Fully break up the data into the Xtrain, Xtest, Xvalid, Ytrain, Ytest, and Yvalid"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
