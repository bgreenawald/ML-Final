{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Prediction Using Recurrent Neural Networks 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import timeit\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(\"df_weather_scaled_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_city = \"Charlotte\"\n",
    "\n",
    "full_df = full_df[full_df[\"city\"] == current_city]\n",
    "\n",
    "min_dataset = 0.54\n",
    "max_dataset = 99.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.array([y[0:4] for y in full_df.datetime])\n",
    "\n",
    "train = full_df[years < '2016']\n",
    "valid = full_df[years == '2016']\n",
    "test = full_df[years > '2016']\n",
    "\n",
    "if(train.shape[0] + valid.shape[0] + test.shape[0] != years.shape[0]):\n",
    "    raise Exception(\"Partition did not work\")\n",
    "    \n",
    "# Drop the city and timestamp for all three\n",
    "train.drop([\"city\", \"datetime\"], inplace=True, axis=1)\n",
    "valid.drop([\"city\", \"datetime\"], inplace=True, axis=1)\n",
    "test.drop([\"city\", \"datetime\"], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataSet(object):\n",
    "    def __init__(self, x, y):\n",
    "        self._num_examples = len(x)\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "        self._epochs_done = 0\n",
    "        self._index_in_epoch = 0\n",
    "        np.random.seed(123456)\n",
    "        # Shuffle the data\n",
    "        perm = np.arange(self._num_examples)\n",
    "        print(perm)\n",
    "        np.random.shuffle(perm)\n",
    "        self._x = [self._x[i] for i in perm]\n",
    "        self._y = [self._y[i] for i in perm]\n",
    "        random.seed(123456)\n",
    "    @property\n",
    "    def features(self):\n",
    "        return self._x\n",
    "    @property\n",
    "    def response(self):\n",
    "        return self._y\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "    @property\n",
    "    def epochs_done(self):\n",
    "        return self._epochs_done\n",
    "\n",
    "    def reset_batch_index(self):\n",
    "        self._index_in_epoch = 0\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        done = False\n",
    "\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # After each epoch we update this\n",
    "            self._epochs_done += 1\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._x = self._x\n",
    "            self._y = self._y \n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            done = True\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "    \n",
    "        return self._x[start:end], self._y[start:end], done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 24\n",
    "\n",
    "train_x = [] \n",
    "train_y = []\n",
    "baseline_err = 0\n",
    "\n",
    "for i in range(train.shape[0] - seq_len):\n",
    "    train_x.append([x for x in train.iloc[i:i+seq_len, :].values])\n",
    "    train_y.append([y for y in train.iloc[i+1:i+seq_len+1, -7:].values])\n",
    "    \n",
    "\n",
    "train_data2 = DataSet(train_x, train_y)\n",
    "del train_x, train_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_x = [] \n",
    "valid_y = []\n",
    "\n",
    "for i in range(valid.shape[0] - seq_len):\n",
    "    valid_x.append([x for x in valid.iloc[i:i+seq_len, :].values])\n",
    "    valid_y.append([y for y in valid.iloc[i+1:i+seq_len+1, -7:].values])\n",
    "\n",
    "valid_data2 = DataSet(valid_x, valid_y)\n",
    "del valid_x, valid_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [] \n",
    "test_y = []\n",
    "baseline_accuracy = []\n",
    "for i in range(test.shape[0] - seq_len):\n",
    "    test_x.append([x for x in test.iloc[i:i+seq_len, :].values])\n",
    "    test_y.append([y for y in test.iloc[i+1:i+seq_len+1, -7:].values])\n",
    "    baseline_accuracy.append(test.iloc[i:i+seq_len, -7:].values == test.iloc[i+1:i+seq_len+1, -7:].values)\n",
    "test_data2 = DataSet(test_x, test_y)\n",
    "del test_x, test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_save_d2(modelDir,train,valid,cell,cellType,input_dim=1,hidden_dim=100,\n",
    "                          seq_size = 12,max_itr=200,keep_prob=0.5, batch_size=32, num_epochs=10,log=500,save=1000):\n",
    "    graph2 = tf.Graph()\n",
    "    with graph2.as_default():\n",
    "        # input place holders\n",
    "        # input Shape: [# training examples, sequence length, # features]\n",
    "        x = tf.placeholder(tf.float32,[None,seq_size,input_dim],name=\"x_in\")\n",
    "        # label Shape: [# training examples, sequence length, # classes]\n",
    "        y = tf.placeholder(tf.float32,[None,seq_size,7],name=\"y_in\")\n",
    "        dropout = tf.placeholder(tf.float32,name=\"dropout_in\")\n",
    "        \n",
    "        # cell = tf.contrib.rnn.MultiRNNCell([cell, cell])\n",
    "        cell = tf.nn.rnn_cell.DropoutWrapper(cell)\n",
    "        # RNN output Shape: [# training examples, sequence length, # hidden] \n",
    "        outputs, _ = tf.nn.dynamic_rnn(cell,x,dtype=tf.float32)\n",
    "        \n",
    "        \n",
    "        # weights for output dense layer (i.e., after RNN)\n",
    "        # W shape: [# hidden, 1]\n",
    "        W_out = tf.Variable(tf.random_normal([hidden_dim,7]),name=\"w_out\") \n",
    "        # b shape: [1]\n",
    "        b_out = tf.Variable(tf.random_normal([7]),name=\"b_out\")\n",
    "    \n",
    "        # output dense layer:\n",
    "        num_examples = tf.shape(x)[0] \n",
    "        # convert W from [# hidden, 1] to [# training examples, # hidden, 1]\n",
    "        # step 1: add a new dimension at index 0 using tf.expand_dims\n",
    "        w_exp= tf.expand_dims(W_out,0)\n",
    "        # step 2: duplicate W for 'num_examples' times using tf.tile\n",
    "        W_repeated = tf.tile(w_exp,[num_examples,1,1])\n",
    "        \n",
    "        # Dense Layer calculation: \n",
    "        # [# training examples, sequence length, # hidden] *\n",
    "        # [# training examples, # hidden, 1] = [# training examples, sequence length]\n",
    "        \n",
    "        y_pred = tf.matmul(outputs,W_repeated)\n",
    "        y_pred = tf.add(y_pred, b_out, name=\"y_out\")\n",
    "        # Actually, y_pred: [# training examples, sequence length, 1]\n",
    "        # Remove last dimension using tf.squeeze\n",
    "        # y_pred = tf.squeeze(y_pred,name=\"y_pred\")\n",
    "        \n",
    "        # Cost & Training Step\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_pred, labels=y))\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "        saver=tf.train.Saver()\n",
    "        \n",
    "        # Run Session\n",
    "    with tf.Session(graph=graph2) as sess2:\n",
    "        # initialize variables\n",
    "        sess2.run(tf.global_variables_initializer())\n",
    "        # Run for 1000 iterations (1000 is arbitrary, need a validation set to tune!)\n",
    "        start=timeit.default_timer()\n",
    "        epoch_counter = 0 # Keep track of our epochs\n",
    "        i = 0 # Keep track of our iterations\n",
    "        \n",
    "        print('Training %s ...'%cellType)\n",
    "        while True: # If we train more, would we overfit? Try 10000\n",
    "            i += 1\n",
    "            trainX, trainY, done = train.next_batch(batch_size)\n",
    "            # See if we are done with our epochs\n",
    "            if done:\n",
    "                epoch_counter += 1\n",
    "                print(\"Done with epoch \" + str(epoch_counter))\n",
    "                if epoch_counter + 1 > num_epochs:\n",
    "                    break\n",
    "                \n",
    "            _, train_err = sess2.run([train_op,cost],feed_dict={x:trainX,y:trainY,dropout:keep_prob})\n",
    "            if i==0:\n",
    "                print('  step, train err= %6d: %8.5f' % (0,train_err)) \n",
    "            elif  (i+1) % log == 0: \n",
    "                print('  step, train err= %6d: %8.5f' % (i+1,train_err)) \n",
    "                \n",
    "                # Get validation error\n",
    "                valid_err = sess2.run(cost,feed_dict={x:valid.features,y:valid.response,dropout:1})\n",
    "                print('  step, validation err= %6d: %8.5f' % (i+1,valid_err)) \n",
    "            if i>0 and (i+1) % save == 0:    \n",
    "                modelPath= saver.save(sess2,\"%s/model_%s\"%(modelDir,cellType),global_step=i+1)\n",
    "                print(\"model saved:%s\"%modelPath)    \n",
    "        \n",
    "        # Save model at the end\n",
    "        modelPath= saver.save(sess2,\"%s/modelF_%s\"%(modelDir,cellType),global_step=i+1)\n",
    "        print(\"model saved:%s\"%modelPath)    \n",
    "        end=timeit.default_timer()        \n",
    "        print(\"Training time : %10.5f\"%(end-start))\n",
    "       \n",
    "    return i + 1\n",
    "\n",
    "input_dim=19 # dim > 1 for multivariate time series\n",
    "hidden_dim=100 # number of hiddent units h\n",
    "max_itr=2000 # number of training iterations\n",
    "keep_prob=0.5\n",
    "modelDir='modelDir2'\n",
    "log=100\n",
    "save=5000\n",
    "batch_size=16\n",
    "num_epochs=1\n",
    "\n",
    "# Different RNN Cell Types\n",
    "RNNcell = rnn.BasicRNNCell(hidden_dim)\n",
    "cellType = \"RNN\"\n",
    "\n",
    "# Build models and save model\n",
    "end_itr = build_and_save_d2(modelDir=modelDir,\n",
    "                 train=train_data2,\n",
    "                 valid=valid_data2,\n",
    "                 cell=RNNcell,\n",
    "                 cellType=cellType,\n",
    "                 input_dim=input_dim,\n",
    "                 hidden_dim=hidden_dim,\n",
    "                 seq_size=seq_len,\n",
    "                 max_itr=max_itr,\n",
    "                 keep_prob=keep_prob,\n",
    "                 batch_size=batch_size,\n",
    "                 num_epochs=num_epochs,\n",
    "                 log=log,\n",
    "                 save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_predict2(test,modelDir,cellType,itr,seq_size):\n",
    "    with tf.Session() as sess2:\n",
    "        print (\"Load model:%s-%s\"%(modelDir,itr))\n",
    "        saver = tf.train.import_meta_graph(\"%s/modelF_%s-%s.meta\"%(modelDir,cellType,itr))\n",
    "        saver.restore(sess2,tf.train.latest_checkpoint(\"%s\"%modelDir))\n",
    "        graph2 = tf.get_default_graph()\n",
    "        \n",
    "        x2 = graph2.get_tensor_by_name(\"x_in:0\")\n",
    "        dropout2= graph2.get_tensor_by_name(\"dropout_in:0\")\n",
    "        y_pred_2 = graph2.get_tensor_by_name(\"y_out:0\")\n",
    "        \n",
    "        predicted_vals_all= sess2.run(y_pred_2, feed_dict={ x2: test.features, dropout2:1})\n",
    "        # Get last item in each predicted sequence:\n",
    "        predicted_vals = predicted_vals_all[:,seq_size-1]\n",
    "    return predicted_vals\n",
    "        \n",
    "# Load and predict\n",
    "predicted_vals_rnn=load_and_predict2(test_data2,modelDir,cellType,end_itr,seq_len)\n",
    "\n",
    "print(predicted_vals_rnn)\n",
    "# Compute MSE\n",
    "# step 2: get ground-truth\n",
    "actual_test= np.array([x[-1] for x in test_data2.response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_test= np.array([x[-1] for x in test_data2.response])\n",
    "\n",
    "sum(np.argmax(actual_test, axis=1) == np.argmax(predicted_vals_rnn, axis=1))/len(actual_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
